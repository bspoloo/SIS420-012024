{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorio 4(Aplicacion de Regularizacion - Regresion Logistica) Grupo 1\n",
    " <h3>En este laboratorio se hizo el uso del dataset para aplicar la regularización y sin utilizar regularización a la Regresion Logistica, y como siguiente se presento los resultados de ambas experiencias<h3>\n",
    " <HR>\n",
    " <h3>\n",
    "  NOMBRE: POLO ORELLANA BRAYAN SIMON <br>\n",
    "  CARRERA: INGENIERIA DE SISTEMAS <BR>\n",
    "  FECHA: 26/03/2024 <BR>\n",
    "\n",
    "  * [Enlace de invitacion para ser colaborador](https://github.com/bspoloo/SIS420-012024/invitations)\n",
    "  \n",
    "  * [Enlace al git hub](https://github.com/bspoloo/SIS420-012024/tree/main/Laboratorios/Laboratorio%202)\n",
    "  \n",
    "  * [Enlace al Colab](https://colab.research.google.com/github/bspoloo/SIS420-012024/blob/main/Laboratorios/Laboratorio%202/Laboratorio%202.ipynb?hl=es)\n",
    " <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el laboratorio hizo uso del para entrenar el modelo de **Regresion Logistica** aplicado regularizacion y predecir si un paciente tiene alguna enfermedad cardiovascular.\n",
    "\n",
    "Estos problemas a menudo se deben a la aterosclerosis. Esta afección ocurre cuando la grasa y el colesterol se acumulan en las paredes del vaso sanguíneo (arteria). El enlace al dataset es [Cardiovascular Disease dataset](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset).\n",
    "\n",
    "El archivo `cardiovascular_diseases_dv3.csv` contiene un conjunto de datos de entrenamiento de datos si un paciente tiene una enfermedad cardiovascular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importo todas las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando la libreria os para manejos de directorios\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np\n",
    "\n",
    "#importamos pandas para el manejo del dataset, y separarlos dentro de una matriz\n",
    "import pandas as pd\n",
    "\n",
    "#esta tabulate nos sirve para hacer tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "#Para separa el 20% y 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos del dataset\n",
    "\n",
    "cargamos los datos haciendo el uso de la libreria **Pandas** que  es una herramienta poderosa y versátil utilizada para manipulación y análisis de datos. Ofrece estructuras de datos flexibles y eficientes para trabajar con datos tabulares, como hojas de cálculo en Excel o tablas SQL. Algunas de las funcionalidades clave de pandas incluyen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>AP_HIGH</th>\n",
       "      <th>AP_LOW</th>\n",
       "      <th>CHOLESTEROL</th>\n",
       "      <th>GLUCOSE</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>ALCOHOL</th>\n",
       "      <th>PHYSICAL_ACTIVITY</th>\n",
       "      <th>CARDIO_DISEASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68778</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68779</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68780</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68781</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68782</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68783 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  GENDER  HEIGHT  WEIGHT  AP_HIGH  AP_LOW  CHOLESTEROL  GLUCOSE  \\\n",
       "0       50       2     168      62      110      80            1        1   \n",
       "1       55       1     156      85      140      90            3        1   \n",
       "2       52       1     165      64      130      70            3        1   \n",
       "3       48       2     169      82      150     100            1        1   \n",
       "4       48       1     156      56      100      60            1        1   \n",
       "...    ...     ...     ...     ...      ...     ...          ...      ...   \n",
       "68778   53       2     168      76      120      80            1        1   \n",
       "68779   62       1     158     126      140      90            2        2   \n",
       "68780   52       2     183     105      180      90            3        1   \n",
       "68781   61       1     163      72      135      80            1        2   \n",
       "68782   56       1     170      72      120      80            2        1   \n",
       "\n",
       "       SMOKE  ALCOHOL  PHYSICAL_ACTIVITY  CARDIO_DISEASE  \n",
       "0          0        0                  1               0  \n",
       "1          0        0                  1               1  \n",
       "2          0        0                  0               1  \n",
       "3          0        0                  1               1  \n",
       "4          0        0                  0               0  \n",
       "...      ...      ...                ...             ...  \n",
       "68778      1        0                  1               0  \n",
       "68779      0        0                  1               1  \n",
       "68780      0        1                  0               1  \n",
       "68781      0        0                  0               1  \n",
       "68782      0        0                  1               0  \n",
       "\n",
       "[68783 rows x 12 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargamos el dataset a un dataframe\n",
    "df = pd.read_csv('cardiovascular_diseases_dv3.csv', delimiter=';')\n",
    "\n",
    "#mostramos el dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del dataset\n",
    "Hacemos un analisis del dataset mostrando su informacion usando la funcion de `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68783 entries, 0 to 68782\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   AGE                68783 non-null  int64\n",
      " 1   GENDER             68783 non-null  int64\n",
      " 2   HEIGHT             68783 non-null  int64\n",
      " 3   WEIGHT             68783 non-null  int64\n",
      " 4   AP_HIGH            68783 non-null  int64\n",
      " 5   AP_LOW             68783 non-null  int64\n",
      " 6   CHOLESTEROL        68783 non-null  int64\n",
      " 7   GLUCOSE            68783 non-null  int64\n",
      " 8   SMOKE              68783 non-null  int64\n",
      " 9   ALCOHOL            68783 non-null  int64\n",
      " 10  PHYSICAL_ACTIVITY  68783 non-null  int64\n",
      " 11  CARDIO_DISEASE     68783 non-null  int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 6.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con la siguiente informacion se puede ver lo siguiente, el cual son las caracteristicas del dataset:\n",
    "\n",
    "**Variables de entrada(X):**\n",
    "\n",
    "1. **age(Edad).-** Se refiere a la edad del paciente en años.\n",
    "2. **gender(Genero).-** Hace referencia al genero del paciente, 1 si es hombre y 2 si es mujer.\n",
    "3. **height(Altura).-** Es la altura del paciente medido en cm.\n",
    "4. **weight(Peso).-** Es el peso del paciente medido en Kg\n",
    "5. **ap_hight(Presión arterial sistólica).-** Presión arterial sistólica del paciente.\n",
    "6. **ap_low(Presión arterial diastólica).-** Presión arterial diastólica del paciente.\n",
    "7. **cholesterol(Colesterol).-** Nivel de colesterol en el paciente donde. 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal.\n",
    "8. **glocose(Glucosa).-** Nivel de glucosa del paciente donde. 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal.\n",
    "9. **smoke(Fuma).-** Indica si el paciente fuma. 1:Si y 2:No.\n",
    "10. **alcohol(alcohol).-** Indica si el paciente consume alcohol. 1:Si y 2:No.\n",
    "11. **fhisycal activity(Actividad fisica).-** Indical si el paciente realiza algun tipo de actividad fisica donde. 1:Si y 2:No.\n",
    "\n",
    "**Variable de salida(y):**\n",
    "\n",
    "1. **cardiovascular disease(Enfermedad cardiovascular).-** Presencia o ausencia de enfermedad cardiovascular, donde: 1:Si y 2:No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion del 80% de los datos para entrenamiento y 20% para pruebas\n",
    "\n",
    "Haremos uso de la libreria `sklearn` haciendo uso de su funcion `train_test_split()`, donde recibe como parametros:\n",
    "\n",
    "`Arrays o matrices de características (X): `Estos son los datos que se utilizarán para hacer predicciones. Por lo general, son las variables independientes o características del conjunto de datos.\n",
    "\n",
    "`test_size (opcional):` Este parámetro especifica el tamaño del conjunto de prueba. Puede ser un número decimal entre 0 y 1, que representa el porcentaje del conjunto de datos que se asignará al conjunto de prueba, o puede ser un entero que representa el número absoluto de muestras en el conjunto de prueba. Por ejemplo, si test_size=0.2, se asignará el 20% del conjunto de datos al conjunto de prueba.\n",
    "\n",
    "`train_size (opcional):` Este parámetro especifica el tamaño del conjunto de entrenamiento. Al igual que test_size, puede ser un número decimal entre 0 y 1 o un entero que representa el número absoluto de muestras en el conjunto de entrenamiento. Si no se proporciona, se calcula automáticamente como 1 - test_size.\n",
    "\n",
    "`random_state (opcional):` Este parámetro permite establecer una semilla para la generación de números pseudoaleatorios. Esto garantiza que la división de los datos sea reproducible. Si se establece en un número entero, el resultado será el mismo cada vez que se ejecute el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]         Y\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "      50       1       173        72     120      70       1       1       0         0       1           1\n",
      "      62       2       174        52     120      80       1       1       1         0       1           1\n",
      "      46       2       156        62     115      70       1       1       0         0       1           0\n",
      "      58       1       158        90     140      90       1       1       0         0       1           1\n",
      "      62       1       156        90     160      80       3       3       0         0       1           0\n",
      "      60       1       151        44     120      80       1       2       0         0       1           0\n",
      "      40       1       156        56     120      70       1       1       0         0       1           0\n",
      "      45       1       157        43     120      80       1       1       0         0       1           0\n",
      "      56       1       167        78     130      80       3       3       0         0       1           1\n",
      "      40       2       174        82     120      80       1       1       1         0       1           0\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 55026 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 13757 de ejemplos\n",
      "La cantidad total de ejemplos es de: 68783 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "# usamos la libreria train_test_split que nos ayudara a separar el 80% y 20% de los datos.\n",
    "train_dataset, test_dataset = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "#Separamos en X_test los datos, pero dropeando nuestra y que seria 'CARDIO_DISEASE'\n",
    "X_test = test_dataset.drop(['CARDIO_DISEASE'], axis=1).values\n",
    "#Separamos en y_test los datos, pero solo cargando la columna de 'CARDIO_DISEASE', ya que esa sera nuestra y\n",
    "y_test = test_dataset['CARDIO_DISEASE'].values\n",
    "m_test = len(y_test)\n",
    "\n",
    "# tomamos train_dataset, seleccionamos las columnas para X_train y la columna 'CARDIO_DISEASE' para y_train\n",
    "X_train = train_dataset.drop(['CARDIO_DISEASE'], axis=1).values\n",
    "y_train = train_dataset['CARDIO_DISEASE'].values\n",
    "m_train = len(y_train)\n",
    "\n",
    "\n",
    "#Imprimimos algunos datos:\n",
    "# imprimir todos las X de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'Y'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:10.0f}{:10.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}{:8.0f}{:12.0f}'.format(\n",
    "        X_train[i, 0], X_train[i, 1], X_train[i, 2], X_train[i, 3], X_train[i, 4], X_train[i, 5], X_train[i, 6], X_train[i, 7], X_train[i, 8], X_train[i, 9], X_train[i, 10], y_train[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(train_dataset)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(test_dataset)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para la Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. En este caso\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #Creamos el promedio de cada filaa de X\n",
    "    #media de cada columna\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    \n",
    "    #desviacion estandar de cada fila de X\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para el calculo de la sigmoide\n",
    "\n",
    "También conocida como la función logística, es una función matemática que toma cualquier número real como entrada y devuelve un valor en el rango de 0 a 1. Donde nuestra **Z** es nuestra hipotesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # Calcula la sigmoide de una entrada z\n",
    "    # convierte la intrada a un arreglo numpy\n",
    "    z = np.array(z)\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularCostoCR(theta, X, y, lambda_):\n",
    "    # Inicializar algunos valores utiles\n",
    "    m = y.size  # numero de ejemplos de entrenamiento\n",
    "\n",
    "    J = 0\n",
    "    \n",
    "    # temp = theta.copy()\n",
    "    # temp[0] = 0\n",
    "    \n",
    "    #hacemos el uso de la funcion sigmoid\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "    # Calculamos el término de regularización (sin incluir el primer término de theta)\n",
    "    regularization_term = (lambda_ / (2 * m)) * np.sum(np.square(theta[1:]))\n",
    "\n",
    "    # Sumamos el término de regularización al costo total\n",
    "    J += regularization_term\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de descenso por el gradiente con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descensoGradienteCR(theta, X, y, alpha, lambda_, num_iters):\n",
    "    # Inicializa algunos valores\n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "\n",
    "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X.dot(theta.T))\n",
    "        \n",
    "        # Calcula el término de regularización (excepto para el término de sesgo theta[0])\n",
    "        regularization_term = (lambda_ / m) * theta[1:]\n",
    "        \n",
    "        theta[0] -= alpha * (1 / m) * np.sum(h - y)\n",
    "        theta[1:] -= alpha * ((1 / m) * (X[:, 1:].T.dot(h - y)) + regularization_term)\n",
    "\n",
    "        # Calcula y guarda el costo en cada iteración\n",
    "        J_history.append(calcularCostoCR(theta, X, y, lambda_))\n",
    "        \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo sin regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularCostoSR(theta, X, y):\n",
    "    # Inicializar algunos valores utiles\n",
    "    m = y.size  # numero de ejemplos de entrenamiento\n",
    "\n",
    "    J = 0\n",
    "    \n",
    "    #hacemos el uso de la funcion sigmoid\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de descenso por el gradiente sin regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descensoGradienteSR(theta, X, y, alpha, num_iters):\n",
    "    # Inicializa algunos valores\n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "\n",
    "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X.dot(theta.T))\n",
    "        theta = theta - (alpha / m) * (h - y).dot(X)\n",
    "\n",
    "        J_history.append(calcularCostoSR(theta, X, y))\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Usando regularizacion\n",
    "\n",
    "La regularización es una técnica utilizada en el aprendizaje automático para prevenir el **sobreajuste (overfitting)** de un modelo a los datos de entrenamiento.\n",
    "\n",
    "El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento y captura el ruido o las fluctuaciones aleatorias en los datos en lugar de aprender la verdadera relación subyacente entre las características y la variable objetivo. Esto puede resultar en un rendimiento deficiente del modelo cuando se enfrenta a nuevos datos que no formaban parte del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Regresion Logistica\n",
    "\n",
    "Carga de los datos para la regresion logistica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]         Y\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "      50       1       173        72     120      70       1       1       0         0       1           1\n",
      "      62       2       174        52     120      80       1       1       1         0       1           1\n",
      "      46       2       156        62     115      70       1       1       0         0       1           0\n",
      "      58       1       158        90     140      90       1       1       0         0       1           1\n",
      "      62       1       156        90     160      80       3       3       0         0       1           0\n",
      "      60       1       151        44     120      80       1       2       0         0       1           0\n",
      "      40       1       156        56     120      70       1       1       0         0       1           0\n",
      "      45       1       157        43     120      80       1       1       0         0       1           0\n",
      "      56       1       167        78     130      80       3       3       0         0       1           1\n",
      "      40       2       174        82     120      80       1       1       1         0       1           0\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 55026 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 13757 de ejemplos\n",
      "La cantidad total de ejemplos es de: 68783 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#hacemos una copia de y_train y y_test para usarlo en la regresion lineal multivariable\n",
    "\n",
    "#estos datos seran usados para el entrenamiento\n",
    "X_testCR = X_test.copy()\n",
    "y_testCR = y_test.copy()\n",
    "m_test_CR = len(y_testCR)\n",
    "\n",
    "#estos datos seran usados para el test\n",
    "X_trainCR = X_train.copy()\n",
    "y_trainCR = y_train.copy()\n",
    "m_train_CR = len(y_trainCR)\n",
    "\n",
    "#Imprimimos algunos datos:\n",
    "# imprimir todos las X de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'Y'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:10.0f}{:10.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}{:8.0f}{:12.0f}'.format(\n",
    "        X_trainCR[i, 0], \n",
    "        X_trainCR[i, 1],\n",
    "        X_trainCR[i, 2],\n",
    "        X_trainCR[i, 3], \n",
    "        X_trainCR[i, 4], \n",
    "        X_trainCR[i, 5],\n",
    "        X_trainCR[i, 6], \n",
    "        X_trainCR[i, 7], \n",
    "        X_trainCR[i, 8], \n",
    "        X_trainCR[i, 9], \n",
    "        X_trainCR[i, 10], \n",
    "        y_trainCR[i]\n",
    "    ))\n",
    "\n",
    "#mostramos la cantidad de ejemplos\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(train_dataset)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(test_dataset)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Normalizacion de las caracteristicas\n",
    "\n",
    "Se hace uso de la funcion de `featureNormalize(X) ` donde se recibe un parametro de tipo matriz para normalizar cada dato dentro de ella, retornandome la **matriz normalizda**, **sigma(desviacion estandar)**, y mi **mu(media)**.\n",
    "\n",
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  -0.495  -0.730     1.058    -0.146  -0.393  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   1.281   1.370     1.180    -1.543  -0.393  -0.143  -0.538  -0.396   3.226    -0.238   0.497\n",
      "  -1.087   1.370    -1.024    -0.844  -0.692  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   0.689  -0.730    -0.779     1.112   0.803   0.896  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   1.281  -0.730    -1.024     1.112   1.999  -0.143   2.401   3.085  -0.310    -0.238   0.497\n",
      "   0.985  -0.730    -1.636    -2.102  -0.393  -0.143  -0.538   1.345  -0.310    -0.238   0.497\n",
      "  -1.974  -0.730    -1.024    -1.263  -0.393  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "  -1.235  -0.730    -0.901    -2.172  -0.393  -0.143  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   0.393  -0.730     0.323     0.274   0.205  -0.143   2.401   3.085  -0.310    -0.238   0.497\n",
      "  -1.974   1.370     1.180     0.553  -0.393  -0.143  -0.538  -0.396   3.226    -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_norm_CR, mu_CR, sigma_CR= featureNormalize(X_trainCR)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}'.format(\n",
    "        X_norm_CR[i, 0], \n",
    "        X_norm_CR[i, 1],\n",
    "        X_norm_CR[i, 2], \n",
    "        X_norm_CR[i, 3], \n",
    "        X_norm_CR[i, 4], \n",
    "        X_norm_CR[i, 5],\n",
    "        X_norm_CR[i, 6],\n",
    "        X_norm_CR[i, 7], \n",
    "        X_norm_CR[i, 8], \n",
    "        X_norm_CR[i, 9], \n",
    "        X_norm_CR[i, 10]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Agregamos la columna de unos a nuestra matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.495    -0.730     1.058  -0.146  -0.393  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   1.281     1.370     1.180  -1.543  -0.393  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n",
      "   1.000  -1.087     1.370    -1.024  -0.844  -0.692  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.689    -0.730    -0.779   1.112   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   1.281    -0.730    -1.024   1.112   1.999  -0.143   2.401   3.085    -0.310  -0.238   0.497\n",
      "   1.000   0.985    -0.730    -1.636  -2.102  -0.393  -0.143  -0.538   1.345    -0.310  -0.238   0.497\n",
      "   1.000  -1.974    -0.730    -1.024  -1.263  -0.393  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -1.235    -0.730    -0.901  -2.172  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.393    -0.730     0.323   0.274   0.205  -0.143   2.401   3.085    -0.310  -0.238   0.497\n",
      "   1.000  -1.974     1.370     1.180   0.553  -0.393  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_ready_CR = np.concatenate([np.ones((m_train_CR, 1)), X_norm_CR], axis=1)\n",
    "\n",
    "# print(len(X_ready[0]))\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]'\n",
    "))\n",
    "print('-' * 130)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}'.format(\n",
    "        X_ready_CR[i, 0],\n",
    "        X_ready_CR[i, 1], \n",
    "        X_ready_CR[i, 2], \n",
    "        X_ready_CR[i, 3],\n",
    "        X_ready_CR[i, 4], \n",
    "        X_ready_CR[i, 5], \n",
    "        X_ready_CR[i, 6], \n",
    "        X_ready_CR[i, 7], \n",
    "        X_ready_CR[i, 8], \n",
    "        X_ready_CR[i, 9], \n",
    "        X_ready_CR[i, 10], \n",
    "        X_ready_CR[i, 11]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Descenso por el gradiente\n",
    "\n",
    "Al igual que regresion lineal se aplicara el descenso por la gradiente, con la diferencia que aqui se hara el uso de la funcion **sigmoid()**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.1 Cálculo del costo $J(\\theta)$\n",
    "\n",
    "hacemos uso de la funcion def `calcularCosto(X, y, theta, lambda_)`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de funcionamiento de la funcion computeCoste con dos valores diferentes de $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "########################################################################################################\n",
      "con theta:[0.2 3.  0.2 0.1 3.  0.2 1.1 2.  0.7 0.8 5.8 0.9] se obtiene un costo de: nan\n",
      "########################################################################################################\n",
      "con theta:[0.1 2.  0.5 0.2 8.  0.7 1.3 8.  1.7 0.7 7.1 7.2] se obtiene un costo de: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIMETX\\AppData\\Local\\Temp\\ipykernel_4744\\294937797.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n"
     ]
    }
   ],
   "source": [
    "theta_CR=np.array([0.2, 3.0, 0.2,0.1, 3.0, 0.2,1.1, 2.0, 0.7,0.8, 5.8, 0.9])\n",
    "theta_CR1=np.array([0.1, 2.0, 0.5,0.2, 8.0, 0.7,1.3, 8.0, 1.7,0.7, 7.1, 7.2])\n",
    "\n",
    "lambda_ = 1000\n",
    "print(theta_CR.shape[0])\n",
    "print(f\"########################################################################################################\")\n",
    "print(f\"con theta:{ theta_CR } se obtiene un costo de: {calcularCostoCR(theta_CR, X_ready_CR, y_trainCR, lambda_)}\")\n",
    "print(f\"########################################################################################################\")\n",
    "print(f\"con theta:{ theta_CR1 } se obtiene un costo de: {calcularCostoCR(theta_CR ,X_ready_CR, y_trainCR, lambda_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.2Descenso por el gradiente\n",
    "\n",
    "Hacemos uso de la funcion para hacer el calculo del descenso por el gradiente y asi encontrar nuestras **Thetas**, se hizo la modificacion para que la funcion ahora reciba el parametro de ``lamda_``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicializan los parametros $\\theta$ con 0 y la taza de aprendizaje $\\alpha$ con 0.00009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################\n",
      "Los valores de theta calculados son:\n",
      "theta 1: -0.005525687971136652\n",
      "theta 2: 0.2898292545244821\n",
      "theta 3: -0.011653468145171816\n",
      "theta 4: -0.02974982527695866\n",
      "theta 5: 0.1609850732204257\n",
      "theta 6: 0.5465391285126422\n",
      "theta 7: 0.3051217491601402\n",
      "theta 8: 0.2532316903259185\n",
      "theta 9: 0.01318102118910723\n",
      "theta 10: -0.03502721046187477\n",
      "theta 11: -0.03186999591459235\n",
      "theta 12: -0.06943510659835729\n",
      "########################################################################################################\n",
      "con un costo de: 0.5738205658870382 \n"
     ]
    }
   ],
   "source": [
    "#creamos un theta con 19 columnas de ceros\n",
    "theta_CR = np.zeros(len(X_ready_CR[0]))\n",
    "\n",
    "#numero de iteraciones sera 900 y un alpha 0.009\n",
    "num_ite_CR = 900\n",
    "alpha_CR = 0.009\n",
    "lambda_CR = 1000\n",
    "\n",
    "theta_CR, J_historico_CR = descensoGradienteCR(theta_CR, X_ready_CR, y_trainCR, alpha_CR, lambda_CR, num_ite_CR)\n",
    "\n",
    "print(\"########################################################################################################\")\n",
    "print(\"Los valores de theta calculados son:\")\n",
    "i = 0\n",
    "for tht in theta_CR:\n",
    "    i += 1\n",
    "    print(f\"theta {i}: {tht}\")\n",
    "\n",
    "\n",
    "print(f\"########################################################################################################\")\n",
    "#mostramos el ultimo costo, este seria el mejor costo\n",
    "print(f\"con un costo de: { J_historico_CR[-1]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Grafica de la convergencia del costo\n",
    "graficamos el costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Costo J')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(np.arange(len(J_historico_CR)), J_historico_CR, lw=2)\n",
    "pyplot.title(\"Grafica de la convergencia del costo\")\n",
    "pyplot.xlabel('Numero de iteraciones')\n",
    "pyplot.ylabel('Costo J')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo la prueba con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una persona con las caracteristicas: [1, 58, 1, 159, 53, 110, 70, 1, 1, 0, 0, 1] \n",
      "Tiene una probabilidad de tener diabetes de: 25.44330785379769 %\n",
      "Con valores de theta: [-0.00552569  0.28982925 -0.01165347 -0.02974983  0.16098507  0.54653913\n",
      "  0.30512175  0.25323169  0.01318102 -0.03502721 -0.03187    -0.06943511]\n"
     ]
    }
   ],
   "source": [
    "X_array_CR = [1,58,1,159,53,110,70,1,1,0,0,1]\n",
    "X_array_copy_CR = X_array_CR.copy()\n",
    "#Se normaliza las caracteristicas para la prueba. haciendo el uso de mu y sigma calculados anteriormente, solamente los valores despues del primero, porque este es el 1.\n",
    "X_array_CR[1:] = (X_array_CR[1:] - mu_CR) / sigma_CR\n",
    "\n",
    "resultados_CR = sigmoid(np.dot(X_array_CR, theta_CR)) \n",
    "\n",
    "print(f\"Una persona con las caracteristicas: {X_array_copy_CR} \")\n",
    "print(f'Tiene una probabilidad de tener diabetes de: {resultados_CR * 100} %')\n",
    "\n",
    "print(f\"Con valores de theta: { theta_CR }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 Ejemplos de Predicciones\n",
    "\n",
    "Se creo una matriz con 11 ejemplos, donde se hace las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.5.1 Definiendo nuestro umbral clasificador\n",
    "Donde:\n",
    "\n",
    "* Si $h(\\theta)$ >= 0.5, predice \"y = 1\".\n",
    "* Si $h(\\theta)$ < 0.5 , predice \"y = 0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|   AGE |   GENDER |   HEIGHT |   WEIGHT |   AP_HIGH |   AP_LOW |   CHOLESTEROL |   GLUCOSE |   SMOKE |   ALCOHOL |   PHYSICAL_ACTIVITY |   CARDIO_DISEASE |   CARDIO_DISEASE(Si/No) |\n",
      "+=======+==========+==========+==========+===========+==========+===============+===========+=========+===========+=====================+==================+=========================+\n",
      "|    50 |        2 |      168 |       62 |       110 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.257871 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    62 |        1 |      165 |       68 |       150 |       80 |             2 |         1 |       0 |         0 |                   0 |         0.8044   |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    58 |        1 |      153 |       78 |       140 |       90 |             2 |         1 |       0 |         0 |                   1 |         0.771126 |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    46 |        1 |      169 |       64 |       120 |       80 |             3 |         1 |       0 |         0 |                   1 |         0.471481 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    46 |        1 |      158 |       58 |       110 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.229228 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    60 |        2 |      170 |       69 |       120 |       80 |             1 |         1 |       1 |         1 |                   1 |         0.378664 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    52 |        2 |      171 |       98 |       110 |       90 |             1 |         1 |       0 |         0 |                   1 |         0.435304 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    52 |        1 |      153 |       63 |       110 |       70 |             2 |         1 |       0 |         0 |                   1 |         0.304504 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    59 |        2 |      165 |       65 |       120 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.425637 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    64 |        1 |      148 |       50 |       120 |       80 |             2 |         1 |       0 |         0 |                   1 |         0.550959 |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    54 |        2 |      169 |       55 |       120 |       80 |             1 |         1 |       1 |         0 |                   1 |         0.31757  |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "nombres_columnas = ['AGE','GENDER','HEIGHT','WEIGHT','AP_HIGH','AP_LOW','CHOLESTEROL','GLUCOSE','SMOKE','ALCOHOL','PHYSICAL_ACTIVITY','CARDIO_DISEASE', 'CARDIO_DISEASE(Si/No)']\n",
    "\n",
    "matriz_datos_CR = np.array([\n",
    "[50,2,168,62,110,80,1,1,0,0,1],\n",
    "[62,1,165,68,150,80,2,1,0,0,0],\n",
    "[58,1,153,78,140,90,2,1,0,0,1],\n",
    "[46,1,169,64,120,80,3,1,0,0,1],\n",
    "[46,1,158,58,110,80,1,1,0,0,1],\n",
    "[60,2,170,69,120,80,1,1,1,1,1],\n",
    "[52,2,171,98,110,90,1,1,0,0,1],\n",
    "[52,1,153,63,110,70,2,1,0,0,1],\n",
    "[59,2,165,65,120,80,1,1,0,0,1],\n",
    "[64,1,148,50,120,80,2,1,0,0,1],\n",
    "[54,2,169,55,120,80,1,1,1,0,1],\n",
    "])\n",
    "\n",
    "para_tabla = matriz_datos_CR.copy()\n",
    "#creamos un vector parta almacenar cada Y predicha\n",
    "y_pre_CR = []\n",
    "\n",
    "matriz_datos_CR = (matriz_datos_CR- mu_CR) / sigma_CR\n",
    "matriz_datos_CR = np.concatenate([np.ones((len(matriz_datos_CR), 1)), matriz_datos_CR], axis=1)\n",
    "\n",
    "# Calculamos la Y predicha de los 11 ejemplos de prediccion\n",
    "# Calculamos la Y predicha de cada fila de la matriz\n",
    "for j in matriz_datos_CR:\n",
    "    y_pre_CR.append(sigmoid(np.dot(j, theta_CR)))\n",
    "\n",
    "# Convertimos la lista a un array unidimensional\n",
    "\n",
    "y_pre_CR = np.array(y_pre_CR)\n",
    "\n",
    "# usamos umbral para definir si tiene o no la enfermedad\n",
    "y_pre_umbral_CR = (y_pre_CR >= 0.5).astype(int)\n",
    "\n",
    "para_tabla = np.column_stack((para_tabla, y_pre_CR))\n",
    "para_tabla = np.column_stack((para_tabla, y_pre_umbral_CR))\n",
    "# Convertir la matriz en una lista de listas\n",
    "datos_para_tabla = para_tabla.tolist()\n",
    "\n",
    "# Imprimir la tabla\n",
    "print(tabulate(datos_para_tabla, headers=nombres_columnas, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.6 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.6.1 Normalizamos el X_test que es el 20% separado a un incio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_test_CR = (X_testCR- mu_CR) / sigma_CR\n",
    "m_test= len(X_testCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.6.2 Concadenamos unos a matriz X normalizado del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.643    -0.730    -1.024  -0.844  -1.589  -1.183   0.931  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.393    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.541    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.097    -0.730     0.323   2.160   1.999   1.935  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.199    -0.730    -2.982   0.204   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.495    -0.730     0.445  -0.076   1.401   0.896  -0.538  -0.396    -0.310  -0.238  -2.014\n",
      "   1.000   1.281     1.370    -0.534   0.902  -0.991  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.643    -0.730    -1.146   1.671  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.199     1.370     0.078  -0.285   0.205  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n",
      "   1.000   0.393     1.370     0.568  -0.425   0.803   0.896   0.931  -0.396    -0.310  -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_test_ready_CR = np.concatenate([np.ones((m_test_CR, 1)), X_norm_test_CR], axis=1)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}'.format(\n",
    "    X_test_ready_CR[i, 0],\n",
    "    X_test_ready_CR[i, 1],\n",
    "    X_test_ready_CR[i, 2],\n",
    "    X_test_ready_CR[i, 3], \n",
    "    X_test_ready_CR[i, 4],\n",
    "    X_test_ready_CR[i, 5], \n",
    "    X_test_ready_CR[i, 6],\n",
    "    X_test_ready_CR[i, 7], \n",
    "    X_test_ready_CR[i, 8], \n",
    "    X_test_ready_CR[i, 9], \n",
    "    X_test_ready_CR[i, 10], \n",
    "    X_test_ready_CR[i, 11]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.6.3 Hacemos el calculo de Y predicha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]         y     (y) usando el umbral\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.643    -0.730    -1.024  -0.844  -1.589  -1.183   0.931  -0.396    -0.310  -0.238   0.497           0.21              0\n",
      "   1.000   0.393    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.44              0\n",
      "   1.000   0.541    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.45              0\n",
      "   1.000   0.097    -0.730     0.323   2.160   1.999   1.935  -0.538  -0.396    -0.310  -0.238   0.497           0.87              1\n",
      "   1.000  -0.199    -0.730    -2.982   0.204   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497           0.65              1\n",
      "   1.000  -0.495    -0.730     0.445  -0.076   1.401   0.896  -0.538  -0.396    -0.310  -0.238  -2.014           0.71              1\n",
      "   1.000   1.281     1.370    -0.534   0.902  -0.991  -1.183  -0.538  -0.396    -0.310  -0.238   0.497           0.37              0\n",
      "   1.000  -0.643    -0.730    -1.146   1.671  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.43              0\n",
      "   1.000  -0.199     1.370     0.078  -0.285   0.205  -0.143  -0.538  -0.396     3.226  -0.238   0.497           0.42              0\n",
      "   1.000   0.393     1.370     0.568  -0.425   0.803   0.896   0.931  -0.396    -0.310  -0.238   0.497           0.72              1\n"
     ]
    }
   ],
   "source": [
    "y_predicha_CR =[]\n",
    "# Calculamos la Y predicha de cada fila de la matriz\n",
    "for dato in X_test_ready_CR:\n",
    "    y_predicha_CR.append(sigmoid(np.dot(dato, theta_CR.T)))\n",
    "\n",
    "# Convertimos la lista a un array unidimensional\n",
    "y_predicha_CR = np.array(y_predicha_CR)\n",
    "\n",
    "#usando el umbral donde todo aquello que sea >= 0.5 sera 1, y si es menor sera 0\n",
    "y_umbral_CR = (y_predicha_CR >= 0.5).astype(int)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}{:>10s}{:>25s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]','y','(y) usando el umbral'\n",
    "))\n",
    "print('-' * 140)\n",
    "\n",
    "#Mostrando algunos datos\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}{:15.2f}{:15.0f}'.format(\n",
    "    X_test_ready_CR[i, 0],\n",
    "    X_test_ready_CR[i, 1], \n",
    "    X_test_ready_CR[i, 2], \n",
    "    X_test_ready_CR[i, 3],\n",
    "    X_test_ready_CR[i, 4], \n",
    "    X_test_ready_CR[i, 5], \n",
    "    X_test_ready_CR[i, 6],\n",
    "    X_test_ready_CR[i, 7], \n",
    "    X_test_ready_CR[i, 8], \n",
    "    X_test_ready_CR[i, 9], \n",
    "    X_test_ready_CR[i, 10],\n",
    "    X_test_ready_CR[i, 11], \n",
    "    y_predicha_CR[i], \n",
    "    y_umbral_CR[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.6.4 Calculando la precision del entrenamiento:\n",
    "se hace uso del **np.mean**, Calcula la media (promedio) de los valores booleanos. Dado que True se interpreta como 1 y False como 0 en operaciones aritméticas, la media resultante será la proporción de elementos iguales en **y_predicha** e **y_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de entrenamiento: 72.65 %\n"
     ]
    }
   ],
   "source": [
    "print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(y_umbral_CR == y_test) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
